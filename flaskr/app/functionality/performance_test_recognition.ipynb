{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional step for organizing the images (customized for the FEI dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "main_folder = 'FEI_dataset/' \n",
    "\n",
    "# Loop through all files in the main folder\n",
    "for filename in os.listdir(main_folder):\n",
    "    if '-' in filename:\n",
    "        person_id = filename.split('-')[0]  # Get 'X' from 'X-Y'\n",
    "        person_folder = os.path.join(main_folder, person_id)\n",
    "\n",
    "        # Create folder for the person if it doesn't exist\n",
    "        if not os.path.exists(person_folder):\n",
    "            os.makedirs(person_folder)\n",
    "\n",
    "        # Move the image into the corresponding person folder\n",
    "        src = os.path.join(main_folder, filename)\n",
    "        dst = os.path.join(person_folder, filename)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "print(\"Done organizing images into folders\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load feature vectors from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from detection import detect_face_for_testing\n",
    "from anti_spoof import load_antispoof_model\n",
    "from feature_extraction import extract_feature, init_facenet\n",
    "\n",
    "DATASET_PATH = \"LFW_dataset/\" # Path to the dataset folder\n",
    "TUNED_WEIGHTS_PATH = \"facenet_finetuned_weights.h5\"\n",
    "SAVE_PATH = 'results_TUNED_PERFORMANCE/'\n",
    "REF_IMG_INDEX = 0 # The index for the reference images in a particular dataset\n",
    "                   # FEI -> 11\n",
    "                   # LFW -> 0\n",
    "                   # GT  -> 0\n",
    "USE_FINE_TUNED = True # Whether to use the fine-tuned weights or not\n",
    "                   # True  -> Use fine-tuned weights\n",
    "                   # False -> Use the original weights\n",
    "DETECT_SPOOF = False # Whether to use the anti-spoofing model or not\n",
    "                   # True  -> Use the anti-spoofing model\n",
    "                   # False -> Do not use the anti-spoofing model\n",
    "DETECT_ALIGNMENT = False # Whether to use the alignment model or not\n",
    "                   # True  -> Use the alignment model\n",
    "                   # False -> Do not use the alignment model\n",
    "\n",
    "if DETECT_SPOOF:\n",
    "    antispoof_sess, antispoof_input = load_antispoof_model()\n",
    "\n",
    "recognition_model = init_facenet()\n",
    "\n",
    "if USE_FINE_TUNED:\n",
    "    #base_dir = os.path.abspath(os.path.dirname(__file__))\n",
    "    #recognition_model.load_weights(os.path.join(base_dir, \"facenet_finetuned_weights.h5\"))\n",
    "    recognition_model.load_weights(TUNED_WEIGHTS_PATH)\n",
    "\n",
    "ref_feat_vect_dict = {} # Dictionary to store the reference feature vector for each person\n",
    "feat_vect_dict = {} # Dictionary to store the rest of the feature vectors for each person\n",
    "\n",
    "n_undetected = 0 # Number of undetected faces\n",
    "n_unreadable = 0 # Number of unreadable images\n",
    "n_misaligned = 0 # Number of misaligned faces\n",
    "\n",
    "for person in os.listdir(DATASET_PATH):\n",
    "    person_path = os.path.join(DATASET_PATH, person)\n",
    "\n",
    "    feat_vect_dict[person] = []\n",
    "\n",
    "    for i, img_name in enumerate(os.listdir(person_path)):\n",
    "        img_path = os.path.join(person_path, img_name)\n",
    "        img_array = cv2.imread(img_path)\n",
    "\n",
    "        if img_array is None:\n",
    "            print(f\"Could not read image: {img_path}\")\n",
    "            n_unreadable += 1\n",
    "            continue\n",
    "        \n",
    "        face_data, image_rgb = detect_face_for_testing(img_array)\n",
    "        \n",
    "        if face_data is not None:\n",
    "            feature_vector = extract_feature(face_data, image_rgb, recognition_model, DETECT_ALIGNMENT, DETECT_SPOOF) #, antispoof_sess, antispoof_input) # <-- Uncomment this line to use the anti-spoofing model\n",
    "\n",
    "            if feature_vector is None:\n",
    "                n_misaligned += 1\n",
    "                continue\n",
    "\n",
    "            if i == REF_IMG_INDEX:\n",
    "                ref_feat_vect_dict[person] = feature_vector # Add reference feature vector to its corresponding person\n",
    "            else:\n",
    "                feat_vect_dict[person].append(feature_vector) # Add feature vector to its corresponding person\n",
    "        else:\n",
    "            n_undetected += 1\n",
    "            print(\"No face detected\")\n",
    "\n",
    "print(f\"Number of undetected faces: {n_undetected}\")\n",
    "print(f\"Number of misaligned faces: {n_misaligned}\")  \n",
    "print(f\"Number of unreadable images: {n_unreadable}\")        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "# Create positive test for each person cases by matching the reference image with each of the other images\n",
    "pos_test_cases = []\n",
    "\n",
    "for person, feature_vectors in feat_vect_dict.items():\n",
    "    ref_feat_vect = ref_feat_vect_dict.get(person)\n",
    "\n",
    "    if ref_feat_vect is None:\n",
    "        continue\n",
    "\n",
    "    for i in range(len(feature_vectors)):\n",
    "        feat_vect = feature_vectors[i]\n",
    "        pos_test_cases.append((ref_feat_vect, feat_vect, True, person, person)) # Add test case consisting of the feature vectors that are to be compared and the expected value\n",
    "\n",
    "# Create negative tests by randomly matching non-identical reference images. Should constitute 20% of the total test cases\n",
    "num_of_neg_tests = int(len(pos_test_cases)/4)\n",
    "\n",
    "neg_pairs = list(combinations(ref_feat_vect_dict.items(), 2))\n",
    "neg_pairs = neg_pairs[:num_of_neg_tests]\n",
    "neg_test_cases = [(ref_feat_vect1, ref_feat_vect2, False, person1, person2) for (person1, ref_feat_vect1), (person2, ref_feat_vect2) in neg_pairs]\n",
    "random.shuffle(neg_test_cases)\n",
    "\n",
    "# Combine the test cases\n",
    "all_test_cases = pos_test_cases + neg_test_cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Functions used to evaluate the test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from verification import compare_faces_euclidean\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "VERIFICATION_THRESHOLDS = np.arange(0.1, 2.1, 0.1) # Used for comparing the likeness of two feature vectors\n",
    "\n",
    "def run_test(y_true, thresholds=VERIFICATION_THRESHOLDS):\n",
    "    y_pred_li = []\n",
    "    rows = []\n",
    "\n",
    "    # Test the verification functionality for each threshold on each test case pair \n",
    "    for threshold in thresholds:\n",
    "        y_pred = []\n",
    "\n",
    "        for f_vect_1, f_vect_2, has_same_face, p1, p2 in all_test_cases:\n",
    "            prediction = compare_faces_euclidean(f_vect_1, f_vect_2, threshold)\n",
    "            y_pred.append(prediction)\n",
    "\n",
    "            if prediction == has_same_face:\n",
    "                pass\n",
    "            else:\n",
    "                #print(f'Incorrect prediction for persons {p1} and {p2}')\n",
    "                pass\n",
    "        \n",
    "        y_pred_li.append(y_pred)\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        rows.append({\n",
    "            'Threshold': threshold,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-score': f1,\n",
    "            'Undetected': n_undetected,\n",
    "            'Misaligned': n_misaligned\n",
    "        })\n",
    "\n",
    "        print(f\"Threshold: {threshold:.2f}\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\\n\")\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "\n",
    "    return y_pred_li, df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot the ROC curve to find suitable thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import plot_ROC\n",
    "\n",
    "y_true = [test_case[2] for test_case in all_test_cases] # Create list consisting of the correct classifications\n",
    "\n",
    "y_pred_list, test_data = run_test(y_true)\n",
    "\n",
    "plot_ROC(y_true, y_pred_list, VERIFICATION_THRESHOLDS, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotting import plot_conf_mat\n",
    "\n",
    "for y_pred, threshold in zip(y_pred_list, VERIFICATION_THRESHOLDS):\n",
    "    plot_conf_mat(y_true, y_pred, threshold, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Analyze and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the performance metrics of the model on the test data\n",
    "test_data_formatted = test_data.copy()\n",
    "test_data_formatted['Threshold'] = test_data['Threshold'].map('{:.1f}'.format)\n",
    "for col in ['Accuracy', 'Precision', 'Recall', 'F1-score']:\n",
    "    test_data_formatted[col] = test_data[col].map('{:.4f}'.format)\n",
    "\n",
    "test_data_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to CSV and Excel files\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)\n",
    "\n",
    "test_data_formatted.to_csv(f\"{SAVE_PATH}test_results_PERF.csv\", index=False)\n",
    "test_data_formatted.to_excel(f\"{SAVE_PATH}test_results_PERF.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
