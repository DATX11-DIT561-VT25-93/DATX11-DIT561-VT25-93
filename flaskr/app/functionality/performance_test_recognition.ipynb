{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load feature vectors from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from detection import detect_face_for_testing\n",
    "from feature_extraction import extract_feature, init_facenet\n",
    "\n",
    "DATASET_PATH = \"test_images_FEI\"\n",
    "REF_IMG_INDEX = 11 # The index for the reference images in a particular dataset\n",
    "                   # FEI -> 11\n",
    "\n",
    "recognition_model = init_facenet()\n",
    "\n",
    "ref_feat_vect_dict = {} # Dictionary to store the reference feature vector for each person\n",
    "feat_vect_dict = {} # Dictionary to store the rest of the feature vectors for each person\n",
    "\n",
    "j = 0\n",
    "\n",
    "for person in os.listdir(DATASET_PATH):\n",
    "    person_path = os.path.join(DATASET_PATH, person)\n",
    "\n",
    "    feat_vect_dict[person] = []\n",
    "\n",
    "    j += 1\n",
    "\n",
    "    for i, img_name in enumerate(os.listdir(person_path)):\n",
    "        img_path = os.path.join(person_path, img_name)\n",
    "        img_array = cv2.imread(img_path)\n",
    "        face_data, _, image_rgb = detect_face_for_testing(img_array)\n",
    "        \n",
    "        \n",
    "        if face_data is not None:\n",
    "            feature_vector = extract_feature(face_data, image_rgb, recognition_model)\n",
    "\n",
    "            if i == REF_IMG_INDEX:\n",
    "                ref_feat_vect_dict[person] = feature_vector # Add reference feature vector to its corresponding person\n",
    "            else:\n",
    "                feat_vect_dict[person].append(feature_vector) # Add feature vector to its corresponding person\n",
    "        else:\n",
    "            print(\"No face detected\")\n",
    "            \n",
    "    if j > 10: # To ensure not loading the entire dataset when testing the basic test functionality\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "# Create positive test for each person cases by matching the reference image with each of the other images\n",
    "pos_test_cases = []\n",
    "\n",
    "for person, feature_vectors in feat_vect_dict.items():\n",
    "    ref_feat_vect = ref_feat_vect_dict.get(person)\n",
    "\n",
    "    for i in range(len(feature_vectors)):\n",
    "        feat_vect = feature_vectors[i]\n",
    "        pos_test_cases.append((ref_feat_vect, feat_vect, True, person, person)) # Add test case consisting of the feature vectors that are to be compared and the expected value\n",
    "\n",
    "# Create negative tests by randomly matching non-identical reference images. Should constitute 20% of the total test cases\n",
    "num_of_neg_tests = int(len(pos_test_cases)/4)\n",
    "\n",
    "neg_pairs = list(combinations(ref_feat_vect_dict.items(), 2))\n",
    "neg_pairs = neg_pairs[:num_of_neg_tests]\n",
    "neg_test_cases = [(ref_feat_vect1, ref_feat_vect2, False, person1, person2) for (person1, ref_feat_vect1), (person2, ref_feat_vect2) in neg_pairs]\n",
    "random.shuffle(neg_test_cases)\n",
    "\n",
    "# Combine the test cases\n",
    "all_test_cases = pos_test_cases + neg_test_cases\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate the test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from verification import compare_faces_euclidean\n",
    "\n",
    "y_true = [test_case[2] for test_case in all_test_cases] # Create list consisting of the correct classifiers\n",
    "y_pred = []\n",
    "\n",
    "# Test the verification functionality on each test case pair \n",
    "for f_vect_1, f_vect_2, has_same_face, p1, p2 in all_test_cases:\n",
    "    prediction = compare_faces_euclidean(f_vect_1, f_vect_2) #prediction, distance = compare_faces_euclidean(f_vect_1, f_vect_2)\n",
    "    y_pred.append(prediction)\n",
    "    if prediction == has_same_face:\n",
    "        pass\n",
    "    else:\n",
    "        print(f'Incorrect prediction for persons {p1} and {p2}')\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Ploting\n",
    "plt.figure(figsize=(5, 4))\n",
    "plt.imshow(cm, cmap=\"Blues\", interpolation=\"nearest\")\n",
    "plt.colorbar()\n",
    "\n",
    "# Labels\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
